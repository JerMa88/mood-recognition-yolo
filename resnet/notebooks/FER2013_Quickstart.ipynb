{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FER2013 Quickstart (Train & Evaluate)\n",
    "\n",
    "This notebook guides you through downloading FER2013 with KaggleHub, preparing the dataset, training a ResNet-18 classifier on grayscale 48Ã—48 images, and evaluating with confusion matrix and per-class metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180104c4",
   "metadata": {},
   "source": [
    "## 0. Environment Setup\n",
    "Create a virtual environment (optional) and install dependencies. If using Colab or a managed environment, you can skip the venv step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd91225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a venv locally (optional). On notebooks, venv activation is manual.\n",
    "import os, subprocess, shlex\n",
    "use_venv = False  # set True to create local venv\n",
    "venv_dir = '.venv'\n",
    "if use_venv and not os.path.exists(venv_dir):\n",
    "    subprocess.run(shlex.split(f'python -m venv {venv_dir}'), check=True)\n",
    "    print(f'Created {venv_dir}. To activate in a terminal: source {venv_dir}/bin/activate')\n",
    "\n",
    "# Install requirements in current interpreter\n",
    "!pip -q install -r requirements.txt -r requirements-dev.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d75555",
   "metadata": {},
   "source": [
    "## 1. Download and Prepare FER2013 (ImageFolder)\n",
    "This will create `data/train`, `data/val`, and `data/test` with a 75/25 train/val split and the official test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f55df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/prepare_fer2013.py --out-dir data --val-ratio 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52708567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a few samples per class from the training split\n",
    "import os, random\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "root = 'data/train'\n",
    "classes = sorted([d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))])\n",
    "print('Classes:', classes)\n",
    "samples_per_class = 3\n",
    "for cls in classes:\n",
    "    cls_dir = os.path.join(root, cls)\n",
    "    imgs = [os.path.join(cls_dir, f) for f in os.listdir(cls_dir) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
    "    random.shuffle(imgs)\n",
    "    print(f'Class: {cls} (showing {min(samples_per_class, len(imgs))})')\n",
    "    for path in imgs[:samples_per_class]:\n",
    "        display(Image.open(path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be578c",
   "metadata": {},
   "source": [
    "## 2. Train (ResNet-18, grayscale 1-ch, with imbalance handling)\n",
    "- Uses weighted sampling and class-weighted CE\n",
    "- AMP enabled by default (GPU recommended)\n",
    "- Adjust `--epochs` and `--batch-size` to your hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0e9561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "batch = 256 if torch.cuda.is_available() else 64\n",
    "epochs = 10\n",
    "!python scripts/train.py \\\n",
    "--data-dir data \\\n",
    "--out-dir runs/fer18 \\\n",
    "--epochs {epochs} \\\n",
    "--batch-size {batch} \\\n",
    "--img-size 48 \\\n",
    "--arch resnet18 \\\n",
    "--weighted-sampler \\\n",
    "--class-weighted-ce \\\n",
    "--label-smoothing 0.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64a2fd",
   "metadata": {},
   "source": [
    "### Distributed Training (DDP)\n",
    "Run from a terminal (notebooks are not ideal for multi-process). Example:\n",
    "\n",
    "`````\n",
    "CUDA_VISIBLE_DEVICES=0,1 torchrun --standalone --nproc_per_node=2 scripts/train.py \\\n",
    "  --data-dir data --out-dir runs/ddp_fer --epochs 10 --batch-size 256 --img-size 48 --arch resnet18 --weighted-sampler --class-weighted-ce\n",
    "`````\n",
    "Artifacts will be saved under `runs/ddp_fer/` on rank 0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b24f1",
   "metadata": {},
   "source": [
    "Artifacts are saved under `runs/fer18/`:\n",
    "- `best.pt`, `last.pt`\n",
    "- `history.json`, `history.csv`\n",
    "- `loss_curve.png`, `accuracy_curve.png`\n",
    "- `confusion_matrix_epoch*.png`, `confusion_matrix_best.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469d9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves from the run directory\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "run_dir = 'runs/fer18'\n",
    "for fname in ['loss_curve.png', 'accuracy_curve.png', 'confusion_matrix_best.png']:\n",
    "    path = os.path.join(run_dir, fname)\n",
    "    if os.path.exists(path):\n",
    "        display(Image(filename=path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68717c82",
   "metadata": {},
   "source": [
    "## 3. Evaluate on Validation and Test Splits\n",
    "Saves confusion matrix and per-class precision/recall charts, plus a CSV of per-class metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21741668",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/eval_classification.py --data-dir data/val --weights runs/fer18/best.pt --arch resnet18 --img-size 48\n",
    "!python scripts/eval_classification.py --data-dir data/test --weights runs/fer18/best.pt --arch resnet18 --img-size 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076affe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display evaluation artifacts inline if present\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "for fname in ['confusion_matrix.png', 'precision_per_class.png', 'recall_per_class.png']:\n",
    "    if os.path.exists(fname):\n",
    "        display(Image(filename=fname))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1d9abe",
   "metadata": {},
   "source": [
    "Outputs in the working directory: \n",
    "- `confusion_matrix.png`\n",
    "- `precision_per_class.png`\n",
    "- `recall_per_class.png`\n",
    "- `metrics_per_class.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2aa58",
   "metadata": {},
   "source": [
    "## 4. Notes\n",
    "- Adjust batch size if you run on CPU.\n",
    "- Training artifacts: check `runs/fer18/`.\n",
    "- For DDP, prefer a terminal and ensure CUDA is available.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
